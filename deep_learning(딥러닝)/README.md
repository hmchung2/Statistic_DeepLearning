구글에서 올린 자연어 처리 모델 BERT를 사용한다. 한국어 버전 PRE_Data 파라미터들을 다운로드 해야 FINE Tuning 다운스트림 태스크에서 제대로 작동 할수 있다.
특히 한국어는 아직 pre data가 부족해서 파인 튜닝 작업 하기전에 같은 유의어들을 대량으로 딕셔너리 형태로 만들 필요가 있다.
1차적으로 할수 있는건 네이버에서 연관검색어를 대량으로 크롤링을 해서 같은 유의어끼리 묶어줄 수 있다.
